{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# تدريب نموذج T5 العربي على قاموس عكسي\n", "### باستخدام بيانات: riotu-lab/arabic_reverse_dictionary"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["!pip install transformers datasets accelerate -q"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from datasets import load_dataset\n", "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n", "import matplotlib.pyplot as plt\n", "\n", "dataset = load_dataset(\"riotu-lab/arabic_reverse_dictionary\")\n", "dataset[\"train\"][0]"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["definitions = [x['definition'] for x in dataset['train']]\n", "words = [x['word'] for x in dataset['train']]\n", "\n", "print(\"عدد الأمثلة:\", len(definitions))\n", "print(\"أول مثال:\", dataset['train'][0])\n", "\n", "def_lengths = [len(defn.split()) for defn in definitions]\n", "plt.hist(def_lengths, bins=30)\n", "plt.title(\"توزيع طول التعاريف\")\n", "plt.xlabel(\"عدد الكلمات\")\n", "plt.ylabel(\"عدد الأمثلة\")\n", "plt.show()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def preprocess(example):\n", "    return {\n", "        \"input_text\": f\"reverse: {example['word']}\",\n", "        \"target_text\": example['definition']\n", "    }\n", "\n", "processed_dataset = dataset.map(preprocess)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from transformers import AutoTokenizer\n", "\n", "tokenizer = AutoTokenizer.from_pretrained(\"cahya/t5-small-arabic\")\n", "\n", "split_dataset = processed_dataset[\"train\"].train_test_split(test_size=0.1)\n", "train_dataset = split_dataset[\"train\"]\n", "eval_dataset = split_dataset[\"test\"]\n", "\n", "def tokenize(batch):\n", "    input_encodings = tokenizer(batch['input_text'], truncation=True, padding=\"max_length\", max_length=64)\n", "    target_encodings = tokenizer(batch['target_text'], truncation=True, padding=\"max_length\", max_length=64)\n", "    input_encodings[\"labels\"] = target_encodings[\"input_ids\"]\n", "    return input_encodings\n", "\n", "tokenized_train = train_dataset.map(tokenize, batched=True)\n", "tokenized_eval = eval_dataset.map(tokenize, batched=True)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from transformers import AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, Seq2SeqTrainer\n", "\n", "model = AutoModelForSeq2SeqLM.from_pretrained(\"cahya/t5-small-arabic\")\n", "\n", "training_args = Seq2SeqTrainingArguments(\n", "    output_dir=\"./t5_arabic_reverse\",\n", "    evaluation_strategy=\"epoch\",\n", "    learning_rate=2e-5,\n", "    per_device_train_batch_size=16,\n", "    per_device_eval_batch_size=16,\n", "    num_train_epochs=3,\n", "    weight_decay=0.01,\n", "    save_total_limit=2,\n", "    predict_with_generate=True,\n", "    logging_dir='./logs',\n", "    logging_steps=100,\n", ")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["trainer = Seq2SeqTrainer(\n", "    model=model,\n", "    args=training_args,\n", "    train_dataset=tokenized_train,\n", "    eval_dataset=tokenized_eval,\n", "    tokenizer=tokenizer,\n", ")\n", "\n", "trainer.train()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def predict_definition(word):\n", "    input_text = f\"reverse: {word}\"\n", "    input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids\n", "    output_ids = model.generate(input_ids, max_length=64)\n", "    return tokenizer.decode(output_ids[0], skip_special_tokens=True)\n", "\n", "print(predict_definition(\"قلم\"))\n", "print(predict_definition(\"كتاب\"))\n", "print(predict_definition(\"حاسوب\"))"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["model.save_pretrained(\"reverse_dict_t5_arabic\")\n", "tokenizer.save_pretrained(\"reverse_dict_t5_arabic\")"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "version": "3.9"}}, "nbformat": 4, "nbformat_minor": 2}